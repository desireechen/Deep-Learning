{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I use Keras to conduct deep learning. Batch size, training epoch, learning rate, activation function, network weight initialisation and number of neurons in the layers are tuned using GridSearchCV. The best parameters obtained from tuning are used in the final model for prediction and model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the dataset and assign column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['n_pregnant', 'glucose_concentration', 'blood_pressure (mm Hg)', 'skin_thickness (mm)', 'serum_insulin (mu U/ml)',\n",
    "        'BMI', 'pedigree_function', 'age', 'class']\n",
    "df = pd.read_csv(\"pimaindiansdiabetes.csv\",names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_pregnant  glucose_concentration  blood_pressure (mm Hg)  \\\n",
       "0           6                    148                      72   \n",
       "1           1                     85                      66   \n",
       "2           8                    183                      64   \n",
       "3           1                     89                      66   \n",
       "4           0                    137                      40   \n",
       "\n",
       "   skin_thickness (mm)  serum_insulin (mu U/ml)   BMI  pedigree_function  age  \\\n",
       "0                   35                        0  33.6              0.627   50   \n",
       "1                   29                        0  26.6              0.351   31   \n",
       "2                    0                        0  23.3              0.672   32   \n",
       "3                   23                       94  28.1              0.167   21   \n",
       "4                   35                      168  43.1              2.288   33   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      "n_pregnant                 768 non-null int64\n",
      "glucose_concentration      768 non-null int64\n",
      "blood_pressure (mm Hg)     768 non-null int64\n",
      "skin_thickness (mm)        768 non-null int64\n",
      "serum_insulin (mu U/ml)    768 non-null int64\n",
      "BMI                        768 non-null float64\n",
      "pedigree_function          768 non-null float64\n",
      "age                        768 non-null int64\n",
      "class                      768 non-null int64\n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glucose concentration, blood pressure, skin thickness, serum insulin and BMI have zero values which should not be the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_pregnant  glucose_concentration  blood_pressure (mm Hg)  \\\n",
       "count  768.000000             768.000000              768.000000   \n",
       "mean     3.845052             120.894531               69.105469   \n",
       "std      3.369578              31.972618               19.355807   \n",
       "min      0.000000               0.000000                0.000000   \n",
       "25%      1.000000              99.000000               62.000000   \n",
       "50%      3.000000             117.000000               72.000000   \n",
       "75%      6.000000             140.250000               80.000000   \n",
       "max     17.000000             199.000000              122.000000   \n",
       "\n",
       "       skin_thickness (mm)  serum_insulin (mu U/ml)         BMI  \\\n",
       "count           768.000000               768.000000  768.000000   \n",
       "mean             20.536458                79.799479   31.992578   \n",
       "std              15.952218               115.244002    7.884160   \n",
       "min               0.000000                 0.000000    0.000000   \n",
       "25%               0.000000                 0.000000   27.300000   \n",
       "50%              23.000000                30.500000   32.000000   \n",
       "75%              32.000000               127.250000   36.600000   \n",
       "max              99.000000               846.000000   67.100000   \n",
       "\n",
       "       pedigree_function         age       class  \n",
       "count         768.000000  768.000000  768.000000  \n",
       "mean            0.471876   33.240885    0.348958  \n",
       "std             0.331329   11.760232    0.476951  \n",
       "min             0.078000   21.000000    0.000000  \n",
       "25%             0.243750   24.000000    0.000000  \n",
       "50%             0.372500   29.000000    0.000000  \n",
       "75%             0.626250   41.000000    1.000000  \n",
       "max             2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace zero values with NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['glucose_concentration', 'blood_pressure (mm Hg)', 'skin_thickness (mm)', 'serum_insulin (mu U/ml)',\n",
    "        'BMI']\n",
    "\n",
    "for col in columns:\n",
    "    df[col].replace(0, np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no more minimum values indicated as zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>541.000000</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>121.686763</td>\n",
       "      <td>72.405184</td>\n",
       "      <td>29.153420</td>\n",
       "      <td>155.548223</td>\n",
       "      <td>32.457464</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>30.535641</td>\n",
       "      <td>12.382158</td>\n",
       "      <td>10.476982</td>\n",
       "      <td>118.775855</td>\n",
       "      <td>6.924988</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>76.250000</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>32.300000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_pregnant  glucose_concentration  blood_pressure (mm Hg)  \\\n",
       "count  768.000000             763.000000              733.000000   \n",
       "mean     3.845052             121.686763               72.405184   \n",
       "std      3.369578              30.535641               12.382158   \n",
       "min      0.000000              44.000000               24.000000   \n",
       "25%      1.000000              99.000000               64.000000   \n",
       "50%      3.000000             117.000000               72.000000   \n",
       "75%      6.000000             141.000000               80.000000   \n",
       "max     17.000000             199.000000              122.000000   \n",
       "\n",
       "       skin_thickness (mm)  serum_insulin (mu U/ml)         BMI  \\\n",
       "count           541.000000               394.000000  757.000000   \n",
       "mean             29.153420               155.548223   32.457464   \n",
       "std              10.476982               118.775855    6.924988   \n",
       "min               7.000000                14.000000   18.200000   \n",
       "25%              22.000000                76.250000   27.500000   \n",
       "50%              29.000000               125.000000   32.300000   \n",
       "75%              36.000000               190.000000   36.600000   \n",
       "max              99.000000               846.000000   67.100000   \n",
       "\n",
       "       pedigree_function         age       class  \n",
       "count         768.000000  768.000000  768.000000  \n",
       "mean            0.471876   33.240885    0.348958  \n",
       "std             0.331329   11.760232    0.476951  \n",
       "min             0.078000   21.000000    0.000000  \n",
       "25%             0.243750   24.000000    0.000000  \n",
       "50%             0.372500   29.000000    0.000000  \n",
       "75%             0.626250   41.000000    1.000000  \n",
       "max             2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NA values. There are now 392 rows of data instead of initial 768 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pregnant</th>\n",
       "      <th>glucose_concentration</th>\n",
       "      <th>blood_pressure (mm Hg)</th>\n",
       "      <th>skin_thickness (mm)</th>\n",
       "      <th>serum_insulin (mu U/ml)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>392.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.301020</td>\n",
       "      <td>122.627551</td>\n",
       "      <td>70.663265</td>\n",
       "      <td>29.145408</td>\n",
       "      <td>156.056122</td>\n",
       "      <td>33.086224</td>\n",
       "      <td>0.523046</td>\n",
       "      <td>30.864796</td>\n",
       "      <td>0.331633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.211424</td>\n",
       "      <td>30.860781</td>\n",
       "      <td>12.496092</td>\n",
       "      <td>10.516424</td>\n",
       "      <td>118.841690</td>\n",
       "      <td>7.027659</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>10.200777</td>\n",
       "      <td>0.471401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>18.200000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>76.750000</td>\n",
       "      <td>28.400000</td>\n",
       "      <td>0.269750</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>33.200000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>37.100000</td>\n",
       "      <td>0.687000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_pregnant  glucose_concentration  blood_pressure (mm Hg)  \\\n",
       "count  392.000000             392.000000              392.000000   \n",
       "mean     3.301020             122.627551               70.663265   \n",
       "std      3.211424              30.860781               12.496092   \n",
       "min      0.000000              56.000000               24.000000   \n",
       "25%      1.000000              99.000000               62.000000   \n",
       "50%      2.000000             119.000000               70.000000   \n",
       "75%      5.000000             143.000000               78.000000   \n",
       "max     17.000000             198.000000              110.000000   \n",
       "\n",
       "       skin_thickness (mm)  serum_insulin (mu U/ml)         BMI  \\\n",
       "count           392.000000               392.000000  392.000000   \n",
       "mean             29.145408               156.056122   33.086224   \n",
       "std              10.516424               118.841690    7.027659   \n",
       "min               7.000000                14.000000   18.200000   \n",
       "25%              21.000000                76.750000   28.400000   \n",
       "50%              29.000000               125.500000   33.200000   \n",
       "75%              37.000000               190.000000   37.100000   \n",
       "max              63.000000               846.000000   67.100000   \n",
       "\n",
       "       pedigree_function         age       class  \n",
       "count         392.000000  392.000000  392.000000  \n",
       "mean            0.523046   30.864796    0.331633  \n",
       "std             0.345488   10.200777    0.471401  \n",
       "min             0.085000   21.000000    0.000000  \n",
       "25%             0.269750   23.000000    0.000000  \n",
       "50%             0.449500   27.000000    0.000000  \n",
       "75%             0.687000   36.000000    1.000000  \n",
       "max             2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dimensions of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 9)\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate columns into independent variables and target variable. The target variable is changed to integer type. Class 1 means person has diabetes. Class 0 means person does not have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:8]\n",
    "Y = dataset[:, 8].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data into a normal distribution with mean 0 and standard deviation 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "print(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "      <td>3.920000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-9.063045e-18</td>\n",
       "      <td>1.132881e-17</td>\n",
       "      <td>-4.531523e-16</td>\n",
       "      <td>1.087565e-16</td>\n",
       "      <td>1.064908e-16</td>\n",
       "      <td>1.631348e-16</td>\n",
       "      <td>1.812609e-17</td>\n",
       "      <td>1.110223e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "      <td>1.001278e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.029213e+00</td>\n",
       "      <td>-2.161731e+00</td>\n",
       "      <td>-3.739001e+00</td>\n",
       "      <td>-2.108484e+00</td>\n",
       "      <td>-1.196867e+00</td>\n",
       "      <td>-2.120941e+00</td>\n",
       "      <td>-1.269525e+00</td>\n",
       "      <td>-9.682991e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.174265e-01</td>\n",
       "      <td>-7.665958e-01</td>\n",
       "      <td>-6.941640e-01</td>\n",
       "      <td>-7.755315e-01</td>\n",
       "      <td>-6.681786e-01</td>\n",
       "      <td>-6.676780e-01</td>\n",
       "      <td>-7.340909e-01</td>\n",
       "      <td>-7.719850e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.056403e-01</td>\n",
       "      <td>-1.176959e-01</td>\n",
       "      <td>-5.314565e-02</td>\n",
       "      <td>-1.384444e-02</td>\n",
       "      <td>-2.574448e-01</td>\n",
       "      <td>1.621036e-02</td>\n",
       "      <td>-2.131475e-01</td>\n",
       "      <td>-3.793569e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.297185e-01</td>\n",
       "      <td>6.609841e-01</td>\n",
       "      <td>5.878727e-01</td>\n",
       "      <td>7.478426e-01</td>\n",
       "      <td>2.859877e-01</td>\n",
       "      <td>5.718696e-01</td>\n",
       "      <td>4.751644e-01</td>\n",
       "      <td>5.040564e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.271153e+00</td>\n",
       "      <td>2.445459e+00</td>\n",
       "      <td>3.151946e+00</td>\n",
       "      <td>3.223325e+00</td>\n",
       "      <td>5.812990e+00</td>\n",
       "      <td>4.846172e+00</td>\n",
       "      <td>5.497667e+00</td>\n",
       "      <td>4.921123e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  3.920000e+02  3.920000e+02  3.920000e+02  3.920000e+02  3.920000e+02   \n",
       "mean  -9.063045e-18  1.132881e-17 -4.531523e-16  1.087565e-16  1.064908e-16   \n",
       "std    1.001278e+00  1.001278e+00  1.001278e+00  1.001278e+00  1.001278e+00   \n",
       "min   -1.029213e+00 -2.161731e+00 -3.739001e+00 -2.108484e+00 -1.196867e+00   \n",
       "25%   -7.174265e-01 -7.665958e-01 -6.941640e-01 -7.755315e-01 -6.681786e-01   \n",
       "50%   -4.056403e-01 -1.176959e-01 -5.314565e-02 -1.384444e-02 -2.574448e-01   \n",
       "75%    5.297185e-01  6.609841e-01  5.878727e-01  7.478426e-01  2.859877e-01   \n",
       "max    4.271153e+00  2.445459e+00  3.151946e+00  3.223325e+00  5.812990e+00   \n",
       "\n",
       "                  5             6             7  \n",
       "count  3.920000e+02  3.920000e+02  3.920000e+02  \n",
       "mean   1.631348e-16  1.812609e-17  1.110223e-16  \n",
       "std    1.001278e+00  1.001278e+00  1.001278e+00  \n",
       "min   -2.120941e+00 -1.269525e+00 -9.682991e-01  \n",
       "25%   -6.676780e-01 -7.340909e-01 -7.719850e-01  \n",
       "50%    1.621036e-02 -2.131475e-01 -3.793569e-01  \n",
       "75%    5.718696e-01  4.751644e-01  5.040564e-01  \n",
       "max    4.846172e+00  5.497667e+00  4.921123e+00  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardised = scaler.transform(X)\n",
    "data = pd.DataFrame(X_standardised)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to create model. I start off with 2 layers of 8 and 4 neurons each, and a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_116\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_335 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 113\n",
      "Trainable params: 113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    \n",
    "    # Create the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model.\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune batch size and training epochs. The best model (based on highest accuracy score) has batch size of 10 and training epochs of 50. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desiree\\Anaconda3\\envs\\deeplearnproject\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[CV] batch_size=10, epochs=10 ........................................\n",
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.6117 - accuracy: 0.7318\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.4378 - accuracy: 0.7854\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.4006 - accuracy: 0.8084\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3855 - accuracy: 0.8084\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3722 - accuracy: 0.8276\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3614 - accuracy: 0.8391\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.3589 - accuracy: 0.8429\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.3565 - accuracy: 0.8391\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3593 - accuracy: 0.8238\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3393 - accuracy: 0.8582\n",
      "131/131 [==============================] - 0s 38us/step\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.756, total=   2.4s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.6262 - accuracy: 0.7203\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4723 - accuracy: 0.7816\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.4582 - accuracy: 0.7778\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.4432 - accuracy: 0.8008\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 176us/step - loss: 0.4347 - accuracy: 0.7969\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 176us/step - loss: 0.4340 - accuracy: 0.8046\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.4282 - accuracy: 0.8046\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.4169 - accuracy: 0.8084\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.4217 - accuracy: 0.8238\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.4133 - accuracy: 0.8199\n",
      "131/131 [==============================] - 0s 31us/step\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.786, total=   3.2s\n",
      "[CV] batch_size=10, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.6370 - accuracy: 0.6527\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.5199 - accuracy: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.5020 - accuracy: 0.6718\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.4947 - accuracy: 0.7519\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.4889 - accuracy: 0.7672\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4833 - accuracy: 0.7634\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 160us/step - loss: 0.4810 - accuracy: 0.7595\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 153us/step - loss: 0.4755 - accuracy: 0.7710\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 168us/step - loss: 0.4698 - accuracy: 0.7672\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 153us/step - loss: 0.4628 - accuracy: 0.7977\n",
      "130/130 [==============================] - 0s 39us/step\n",
      "[CV] ............ batch_size=10, epochs=10, score=0.792, total=   2.7s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    8.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.6303 - accuracy: 0.7126\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 222us/step - loss: 0.4623 - accuracy: 0.7931\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 207us/step - loss: 0.4009 - accuracy: 0.7931\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3848 - accuracy: 0.8161\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 176us/step - loss: 0.3762 - accuracy: 0.8276\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.3809 - accuracy: 0.8161\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.3698 - accuracy: 0.8314\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 268us/step - loss: 0.3731 - accuracy: 0.8199\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 287us/step - loss: 0.3628 - accuracy: 0.8314\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 218us/step - loss: 0.3603 - accuracy: 0.8391\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 260us/step - loss: 0.3543 - accuracy: 0.8391\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 310us/step - loss: 0.3537 - accuracy: 0.8314\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3404 - accuracy: 0.8391\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 218us/step - loss: 0.3398 - accuracy: 0.8352\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3310 - accuracy: 0.8429\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 310us/step - loss: 0.3297 - accuracy: 0.8582\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 222us/step - loss: 0.3272 - accuracy: 0.8621\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3230 - accuracy: 0.8506\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 253us/step - loss: 0.3175 - accuracy: 0.8582\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 264us/step - loss: 0.3198 - accuracy: 0.8506\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.3200 - accuracy: 0.8659\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 276us/step - loss: 0.3148 - accuracy: 0.8659\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 241us/step - loss: 0.3317 - accuracy: 0.8314\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3207 - accuracy: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.3160 - accuracy: 0.8506\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3024 - accuracy: 0.8659\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3045 - accuracy: 0.8659\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3016 - accuracy: 0.8697\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.2940 - accuracy: 0.8697\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.2978 - accuracy: 0.8736\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.2961 - accuracy: 0.8736\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 188us/step - loss: 0.2905 - accuracy: 0.8812\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 402us/step - loss: 0.2925 - accuracy: 0.8812\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 923us/step - loss: 0.3498 - accuracy: 0.8582\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 375us/step - loss: 0.3041 - accuracy: 0.8659\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 291us/step - loss: 0.2925 - accuracy: 0.8697\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 318us/step - loss: 0.2867 - accuracy: 0.8736\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 356us/step - loss: 0.2829 - accuracy: 0.8736\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 306us/step - loss: 0.2854 - accuracy: 0.8736\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 287us/step - loss: 0.2846 - accuracy: 0.8659\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 203us/step - loss: 0.2838 - accuracy: 0.8697\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.2809 - accuracy: 0.8774\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 176us/step - loss: 0.2815 - accuracy: 0.8736\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.2776 - accuracy: 0.8812\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 203us/step - loss: 0.2864 - accuracy: 0.8736\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.2917 - accuracy: 0.8736\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 199us/step - loss: 0.2874 - accuracy: 0.8697\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 260us/step - loss: 0.2823 - accuracy: 0.8774\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 218us/step - loss: 0.2791 - accuracy: 0.8812\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 257us/step - loss: 0.3395 - accuracy: 0.8544\n",
      "131/131 [==============================] - 0s 53us/step\n",
      "[CV] ............ batch_size=10, epochs=50, score=0.771, total=   5.5s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   13.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 195us/step - loss: 0.6189 - accuracy: 0.7395\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 295us/step - loss: 0.4644 - accuracy: 0.7739\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.4473 - accuracy: 0.8008\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.4398 - accuracy: 0.7931\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.4323 - accuracy: 0.8008\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.4317 - accuracy: 0.7931\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 276us/step - loss: 0.4135 - accuracy: 0.7969\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.4176 - accuracy: 0.8123\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.4067 - accuracy: 0.8199\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3975 - accuracy: 0.8352\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3924 - accuracy: 0.8276\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3937 - accuracy: 0.8314\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3909 - accuracy: 0.8199\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.3952 - accuracy: 0.8391\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.3827 - accuracy: 0.8352\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 122us/step - loss: 0.3789 - accuracy: 0.8391\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.80 - 0s 115us/step - loss: 0.3837 - accuracy: 0.8314\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.90 - 0s 157us/step - loss: 0.3692 - accuracy: 0.8314\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.3675 - accuracy: 0.8352\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 191us/step - loss: 0.3746 - accuracy: 0.8429\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.3566 - accuracy: 0.8544\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.3531 - accuracy: 0.8467\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3650 - accuracy: 0.8391\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 168us/step - loss: 0.3552 - accuracy: 0.8467\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 180us/step - loss: 0.3536 - accuracy: 0.8544\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.3473 - accuracy: 0.8506\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3515 - accuracy: 0.8621\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.3708 - accuracy: 0.8352\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3486 - accuracy: 0.8621\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 161us/step - loss: 0.3403 - accuracy: 0.8582\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3395 - accuracy: 0.8659\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 230us/step - loss: 0.3353 - accuracy: 0.8659\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 195us/step - loss: 0.3369 - accuracy: 0.8582\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3348 - accuracy: 0.8736\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 172us/step - loss: 0.3393 - accuracy: 0.8506\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.3335 - accuracy: 0.8812\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 130us/step - loss: 0.3492 - accuracy: 0.8429\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3389 - accuracy: 0.8621\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.3294 - accuracy: 0.8659\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 157us/step - loss: 0.3275 - accuracy: 0.8736\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.3315 - accuracy: 0.8659\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3212 - accuracy: 0.8659\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3281 - accuracy: 0.8659\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.3244 - accuracy: 0.8774\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.3170 - accuracy: 0.8774\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 238us/step - loss: 0.3180 - accuracy: 0.8659\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.3070 - accuracy: 0.8736\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 207us/step - loss: 0.3110 - accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3154 - accuracy: 0.8697\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 149us/step - loss: 0.3086 - accuracy: 0.8697\n",
      "131/131 [==============================] - 0s 31us/step\n",
      "[CV] ............ batch_size=10, epochs=50, score=0.786, total=   5.0s\n",
      "[CV] batch_size=10, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   18.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.6141 - accuracy: 0.6527\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.5102 - accuracy: 0.6527\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.5015 - accuracy: 0.6832\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 210us/step - loss: 0.4944 - accuracy: 0.7634\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.4902 - accuracy: 0.7557\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.4852 - accuracy: 0.7710\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.4812 - accuracy: 0.7824\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 156us/step - loss: 0.4709 - accuracy: 0.7901\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 179us/step - loss: 0.4754 - accuracy: 0.7786\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 267us/step - loss: 0.4655 - accuracy: 0.7939\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 198us/step - loss: 0.4626 - accuracy: 0.7901\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 175us/step - loss: 0.4688 - accuracy: 0.7901\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 137us/step - loss: 0.4547 - accuracy: 0.7939\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 187us/step - loss: 0.4455 - accuracy: 0.8092\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 179us/step - loss: 0.4365 - accuracy: 0.8168\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 172us/step - loss: 0.4363 - accuracy: 0.8282\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 191us/step - loss: 0.4453 - accuracy: 0.8015\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 214us/step - loss: 0.4252 - accuracy: 0.8244\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 202us/step - loss: 0.4243 - accuracy: 0.8282\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 172us/step - loss: 0.4260 - accuracy: 0.8092\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 130us/step - loss: 0.4160 - accuracy: 0.8321\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 324us/step - loss: 0.4268 - accuracy: 0.8092\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 141us/step - loss: 0.4172 - accuracy: 0.8321\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 267us/step - loss: 0.4249 - accuracy: 0.8244\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 258us/step - loss: 0.4243 - accuracy: 0.8244\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.4213 - accuracy: 0.8130\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 95us/step - loss: 0.4102 - accuracy: 0.8397\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4100 - accuracy: 0.8359\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 134us/step - loss: 0.4090 - accuracy: 0.8321\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 179us/step - loss: 0.4059 - accuracy: 0.8206\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 195us/step - loss: 0.4106 - accuracy: 0.8244\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 168us/step - loss: 0.4033 - accuracy: 0.8359\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 229us/step - loss: 0.4033 - accuracy: 0.8321\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 248us/step - loss: 0.4023 - accuracy: 0.8397\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 431us/step - loss: 0.4001 - accuracy: 0.8130\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 259us/step - loss: 0.3998 - accuracy: 0.8359\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 202us/step - loss: 0.4031 - accuracy: 0.8244\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 256us/step - loss: 0.3999 - accuracy: 0.8168\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 156us/step - loss: 0.3999 - accuracy: 0.8473\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 156us/step - loss: 0.3975 - accuracy: 0.8282\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3939 - accuracy: 0.8321\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 172us/step - loss: 0.3964 - accuracy: 0.8282\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 187us/step - loss: 0.4104 - accuracy: 0.8168\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3970 - accuracy: 0.8321\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 149us/step - loss: 0.3992 - accuracy: 0.8206\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 164us/step - loss: 0.3936 - accuracy: 0.8282\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 191us/step - loss: 0.4065 - accuracy: 0.8206\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 156us/step - loss: 0.4281 - accuracy: 0.8092\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 164us/step - loss: 0.4126 - accuracy: 0.8397\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 160us/step - loss: 0.4022 - accuracy: 0.8206\n",
      "130/130 [==============================] - 0s 38us/step\n",
      "[CV] ............ batch_size=10, epochs=50, score=0.831, total=   4.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   23.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.6874 - accuracy: 0.6935\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 142us/step - loss: 0.6705 - accuracy: 0.7471\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 169us/step - loss: 0.6499 - accuracy: 0.7931\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.6243 - accuracy: 0.8008\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.6024 - accuracy: 0.8084\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.5820 - accuracy: 0.8084\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.5640 - accuracy: 0.8161\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.5483 - accuracy: 0.8238\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - ETA: 0s - loss: 0.5762 - accuracy: 0.80 - 0s 92us/step - loss: 0.5354 - accuracy: 0.8276\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.5210 - accuracy: 0.8238\n",
      "131/131 [==============================] - 0s 30us/step\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.710, total=   2.9s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   26.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "261/261 [==============================] - 0s 31us/step - loss: 0.6844 - accuracy: 0.6552\n",
      "Epoch 2/10\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.6326 - accuracy: 0.6552\n",
      "Epoch 3/10\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.5587 - accuracy: 0.6552\n",
      "Epoch 4/10\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.5120 - accuracy: 0.6552\n",
      "Epoch 5/10\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.5004 - accuracy: 0.6552\n",
      "Epoch 6/10\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4870 - accuracy: 0.6552\n",
      "Epoch 7/10\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4813 - accuracy: 0.6552\n",
      "Epoch 8/10\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.4761 - accuracy: 0.7088\n",
      "Epoch 9/10\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.4692 - accuracy: 0.7893\n",
      "Epoch 10/10\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.4640 - accuracy: 0.7893\n",
      "131/131 [==============================] - 0s 23us/step\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.748, total=   2.6s\n",
      "[CV] batch_size=40, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   28.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "262/262 [==============================] - 0s 53us/step - loss: 0.6877 - accuracy: 0.6260\n",
      "Epoch 2/10\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.6668 - accuracy: 0.6527\n",
      "Epoch 3/10\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.6172 - accuracy: 0.6985\n",
      "Epoch 4/10\n",
      "262/262 [==============================] - 0s 160us/step - loss: 0.5451 - accuracy: 0.7672\n",
      "Epoch 5/10\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.4848 - accuracy: 0.7443\n",
      "Epoch 6/10\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4760 - accuracy: 0.7328\n",
      "Epoch 7/10\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.4756 - accuracy: 0.7443\n",
      "Epoch 8/10\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.4676 - accuracy: 0.7519\n",
      "Epoch 9/10\n",
      "262/262 [==============================] - 0s 76us/step - loss: 0.4619 - accuracy: 0.7634\n",
      "Epoch 10/10\n",
      "262/262 [==============================] - 0s 61us/step - loss: 0.4608 - accuracy: 0.7634\n",
      "130/130 [==============================] - 0s 38us/step\n",
      "[CV] ............ batch_size=40, epochs=10, score=0.823, total=   2.9s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   31.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 46us/step - loss: 0.6688 - accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.6006 - accuracy: 0.6973\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.5163 - accuracy: 0.6973\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4674 - accuracy: 0.7548\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.4324 - accuracy: 0.8008\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 119us/step - loss: 0.4072 - accuracy: 0.7969\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3922 - accuracy: 0.8123\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.3853 - accuracy: 0.8161\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3767 - accuracy: 0.8199\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3724 - accuracy: 0.8199\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 115us/step - loss: 0.3673 - accuracy: 0.8276\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3637 - accuracy: 0.8352\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3594 - accuracy: 0.8352\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 111us/step - loss: 0.3577 - accuracy: 0.8391\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3545 - accuracy: 0.8352\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3525 - accuracy: 0.8391\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 184us/step - loss: 0.3493 - accuracy: 0.8391\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3457 - accuracy: 0.8391\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.3441 - accuracy: 0.8429\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3409 - accuracy: 0.8467\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 86us/step - loss: 0.3375 - accuracy: 0.8544\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 74us/step - loss: 0.3347 - accuracy: 0.8544\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3303 - accuracy: 0.8544\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 138us/step - loss: 0.3267 - accuracy: 0.8544\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 134us/step - loss: 0.3244 - accuracy: 0.8582\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3220 - accuracy: 0.8621\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3197 - accuracy: 0.8659\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3147 - accuracy: 0.8621\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3125 - accuracy: 0.8582\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3101 - accuracy: 0.8506\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.3068 - accuracy: 0.8544\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3055 - accuracy: 0.8697\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 146us/step - loss: 0.3025 - accuracy: 0.8736\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.2994 - accuracy: 0.8736\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.2967 - accuracy: 0.8736\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.2954 - accuracy: 0.8774\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.2927 - accuracy: 0.8774\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.2931 - accuracy: 0.8659\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.2914 - accuracy: 0.8736\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.2886 - accuracy: 0.8812\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 131us/step - loss: 0.2873 - accuracy: 0.8774\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.2867 - accuracy: 0.8851\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.2830 - accuracy: 0.8851\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.2827 - accuracy: 0.8736\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 153us/step - loss: 0.2824 - accuracy: 0.8812\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2800 - accuracy: 0.8774\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 341us/step - loss: 0.2784 - accuracy: 0.8812\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.2771 - accuracy: 0.8851\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.2724 - accuracy: 0.8812\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 113us/step - loss: 0.2763 - accuracy: 0.8736\n",
      "131/131 [==============================] - 0s 23us/step\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.763, total=   5.0s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "261/261 [==============================] - 0s 38us/step - loss: 0.6861 - accuracy: 0.6092\n",
      "Epoch 2/50\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.6645 - accuracy: 0.6552\n",
      "Epoch 3/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.6287 - accuracy: 0.6552\n",
      "Epoch 4/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.5835 - accuracy: 0.6552\n",
      "Epoch 5/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.5353 - accuracy: 0.6552\n",
      "Epoch 6/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.5091 - accuracy: 0.6552\n",
      "Epoch 7/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.5052 - accuracy: 0.6552\n",
      "Epoch 8/50\n",
      "261/261 [==============================] - 0s 54us/step - loss: 0.4978 - accuracy: 0.6552\n",
      "Epoch 9/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.4857 - accuracy: 0.6552\n",
      "Epoch 10/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.4773 - accuracy: 0.6552\n",
      "Epoch 11/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4714 - accuracy: 0.6743\n",
      "Epoch 12/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.4618 - accuracy: 0.8084\n",
      "Epoch 13/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.4570 - accuracy: 0.8008\n",
      "Epoch 14/50\n",
      "261/261 [==============================] - 0s 57us/step - loss: 0.4453 - accuracy: 0.8238\n",
      "Epoch 15/50\n",
      "261/261 [==============================] - 0s 103us/step - loss: 0.4409 - accuracy: 0.8199\n",
      "Epoch 16/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.4351 - accuracy: 0.8199\n",
      "Epoch 17/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.4268 - accuracy: 0.8161\n",
      "Epoch 18/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.4198 - accuracy: 0.8352\n",
      "Epoch 19/50\n",
      "261/261 [==============================] - 0s 57us/step - loss: 0.4130 - accuracy: 0.8391\n",
      "Epoch 20/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.4081 - accuracy: 0.8391\n",
      "Epoch 21/50\n",
      "261/261 [==============================] - 0s 100us/step - loss: 0.4029 - accuracy: 0.8352\n",
      "Epoch 22/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3977 - accuracy: 0.8429\n",
      "Epoch 23/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3923 - accuracy: 0.8352\n",
      "Epoch 24/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3879 - accuracy: 0.8314\n",
      "Epoch 25/50\n",
      "261/261 [==============================] - 0s 57us/step - loss: 0.3833 - accuracy: 0.8238\n",
      "Epoch 26/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3782 - accuracy: 0.8276\n",
      "Epoch 27/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3796 - accuracy: 0.8084\n",
      "Epoch 28/50\n",
      "261/261 [==============================] - 0s 77us/step - loss: 0.3679 - accuracy: 0.8276\n",
      "Epoch 29/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3698 - accuracy: 0.8352\n",
      "Epoch 30/50\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.3667 - accuracy: 0.8314\n",
      "Epoch 31/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3629 - accuracy: 0.8467\n",
      "Epoch 32/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3583 - accuracy: 0.8544\n",
      "Epoch 33/50\n",
      "261/261 [==============================] - 0s 92us/step - loss: 0.3577 - accuracy: 0.8544\n",
      "Epoch 34/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3542 - accuracy: 0.8582\n",
      "Epoch 35/50\n",
      "261/261 [==============================] - 0s 69us/step - loss: 0.3499 - accuracy: 0.8582\n",
      "Epoch 36/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3487 - accuracy: 0.8506\n",
      "Epoch 37/50\n",
      "261/261 [==============================] - 0s 73us/step - loss: 0.3450 - accuracy: 0.8544\n",
      "Epoch 38/50\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.3429 - accuracy: 0.8621\n",
      "Epoch 39/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3404 - accuracy: 0.8582\n",
      "Epoch 40/50\n",
      "261/261 [==============================] - 0s 61us/step - loss: 0.3405 - accuracy: 0.8621\n",
      "Epoch 41/50\n",
      "261/261 [==============================] - 0s 65us/step - loss: 0.3397 - accuracy: 0.8697\n",
      "Epoch 42/50\n",
      "261/261 [==============================] - 0s 107us/step - loss: 0.3357 - accuracy: 0.8544\n",
      "Epoch 43/50\n",
      "261/261 [==============================] - 0s 163us/step - loss: 0.3363 - accuracy: 0.8544\n",
      "Epoch 44/50\n",
      "261/261 [==============================] - 0s 126us/step - loss: 0.3376 - accuracy: 0.8544\n",
      "Epoch 45/50\n",
      "261/261 [==============================] - 0s 165us/step - loss: 0.3290 - accuracy: 0.8582\n",
      "Epoch 46/50\n",
      "261/261 [==============================] - 0s 123us/step - loss: 0.3327 - accuracy: 0.8544\n",
      "Epoch 47/50\n",
      "261/261 [==============================] - 0s 96us/step - loss: 0.3341 - accuracy: 0.8544\n",
      "Epoch 48/50\n",
      "261/261 [==============================] - 0s 84us/step - loss: 0.3302 - accuracy: 0.8659\n",
      "Epoch 49/50\n",
      "261/261 [==============================] - 0s 88us/step - loss: 0.3264 - accuracy: 0.8659\n",
      "Epoch 50/50\n",
      "261/261 [==============================] - 0s 80us/step - loss: 0.3290 - accuracy: 0.8621\n",
      "131/131 [==============================] - 0s 30us/step\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.771, total=   3.7s\n",
      "[CV] batch_size=40, epochs=50 ........................................\n",
      "Epoch 1/50\n",
      "262/262 [==============================] - 0s 34us/step - loss: 0.6805 - accuracy: 0.6412\n",
      "Epoch 2/50\n",
      "262/262 [==============================] - 0s 46us/step - loss: 0.6209 - accuracy: 0.6527\n",
      "Epoch 3/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.5507 - accuracy: 0.6527\n",
      "Epoch 4/50\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.5108 - accuracy: 0.6947\n",
      "Epoch 5/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.4941 - accuracy: 0.7405\n",
      "Epoch 6/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.4774 - accuracy: 0.7481\n",
      "Epoch 7/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4680 - accuracy: 0.7710\n",
      "Epoch 8/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.4674 - accuracy: 0.7672\n",
      "Epoch 9/50\n",
      "262/262 [==============================] - 0s 76us/step - loss: 0.4647 - accuracy: 0.7710\n",
      "Epoch 10/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.4609 - accuracy: 0.7748\n",
      "Epoch 11/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4603 - accuracy: 0.7786\n",
      "Epoch 12/50\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.4577 - accuracy: 0.7786\n",
      "Epoch 13/50\n",
      "262/262 [==============================] - 0s 46us/step - loss: 0.4563 - accuracy: 0.7786\n",
      "Epoch 14/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4554 - accuracy: 0.7824\n",
      "Epoch 15/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4524 - accuracy: 0.7824\n",
      "Epoch 16/50\n",
      "262/262 [==============================] - 0s 72us/step - loss: 0.4524 - accuracy: 0.7786\n",
      "Epoch 17/50\n",
      "262/262 [==============================] - 0s 77us/step - loss: 0.4504 - accuracy: 0.7863\n",
      "Epoch 18/50\n",
      "262/262 [==============================] - 0s 61us/step - loss: 0.4498 - accuracy: 0.7748\n",
      "Epoch 19/50\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.4467 - accuracy: 0.7672\n",
      "Epoch 20/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.4457 - accuracy: 0.7824\n",
      "Epoch 21/50\n",
      "262/262 [==============================] - 0s 95us/step - loss: 0.4437 - accuracy: 0.7863\n",
      "Epoch 22/50\n",
      "262/262 [==============================] - 0s 72us/step - loss: 0.4428 - accuracy: 0.7863\n",
      "Epoch 23/50\n",
      "262/262 [==============================] - 0s 65us/step - loss: 0.4399 - accuracy: 0.7901\n",
      "Epoch 24/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.4418 - accuracy: 0.7901\n",
      "Epoch 25/50\n",
      "262/262 [==============================] - 0s 53us/step - loss: 0.4349 - accuracy: 0.8053\n",
      "Epoch 26/50\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.4309 - accuracy: 0.8015\n",
      "Epoch 27/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.4277 - accuracy: 0.8015\n",
      "Epoch 28/50\n",
      "262/262 [==============================] - 0s 84us/step - loss: 0.4266 - accuracy: 0.8168\n",
      "Epoch 29/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.4236 - accuracy: 0.8053\n",
      "Epoch 30/50\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.4205 - accuracy: 0.7939\n",
      "Epoch 31/50\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.4162 - accuracy: 0.7977\n",
      "Epoch 32/50\n",
      "262/262 [==============================] - 0s 145us/step - loss: 0.4124 - accuracy: 0.8282\n",
      "Epoch 33/50\n",
      "262/262 [==============================] - 0s 122us/step - loss: 0.4095 - accuracy: 0.8130\n",
      "Epoch 34/50\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.4104 - accuracy: 0.8053\n",
      "Epoch 35/50\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.4031 - accuracy: 0.8282\n",
      "Epoch 36/50\n",
      "262/262 [==============================] - 0s 114us/step - loss: 0.4046 - accuracy: 0.8282\n",
      "Epoch 37/50\n",
      "262/262 [==============================] - 0s 111us/step - loss: 0.3948 - accuracy: 0.8244\n",
      "Epoch 38/50\n",
      "262/262 [==============================] - 0s 76us/step - loss: 0.3934 - accuracy: 0.8168\n",
      "Epoch 39/50\n",
      "262/262 [==============================] - 0s 126us/step - loss: 0.3887 - accuracy: 0.8321\n",
      "Epoch 40/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3862 - accuracy: 0.8359\n",
      "Epoch 41/50\n",
      "262/262 [==============================] - 0s 107us/step - loss: 0.3798 - accuracy: 0.8435\n",
      "Epoch 42/50\n",
      "262/262 [==============================] - 0s 69us/step - loss: 0.3816 - accuracy: 0.8397\n",
      "Epoch 43/50\n",
      "262/262 [==============================] - 0s 103us/step - loss: 0.3787 - accuracy: 0.8397\n",
      "Epoch 44/50\n",
      "262/262 [==============================] - 0s 72us/step - loss: 0.3756 - accuracy: 0.8359\n",
      "Epoch 45/50\n",
      "262/262 [==============================] - 0s 92us/step - loss: 0.3709 - accuracy: 0.8435\n",
      "Epoch 46/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3686 - accuracy: 0.8511\n",
      "Epoch 47/50\n",
      "262/262 [==============================] - 0s 72us/step - loss: 0.3683 - accuracy: 0.8550\n",
      "Epoch 48/50\n",
      "262/262 [==============================] - 0s 88us/step - loss: 0.3661 - accuracy: 0.8435\n",
      "Epoch 49/50\n",
      "262/262 [==============================] - 0s 50us/step - loss: 0.3633 - accuracy: 0.8359\n",
      "Epoch 50/50\n",
      "262/262 [==============================] - 0s 80us/step - loss: 0.3595 - accuracy: 0.8511\n",
      "130/130 [==============================] - 0s 15us/step\n",
      "[CV] ............ batch_size=40, epochs=50, score=0.854, total=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   45.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "392/392 [==============================] - 0s 74us/step - loss: 0.5579 - accuracy: 0.7321\n",
      "Epoch 2/50\n",
      "392/392 [==============================] - 0s 138us/step - loss: 0.4567 - accuracy: 0.7832\n",
      "Epoch 3/50\n",
      "392/392 [==============================] - 0s 130us/step - loss: 0.4377 - accuracy: 0.7908\n",
      "Epoch 4/50\n",
      "392/392 [==============================] - 0s 176us/step - loss: 0.4351 - accuracy: 0.7832\n",
      "Epoch 5/50\n",
      "392/392 [==============================] - 0s 176us/step - loss: 0.4294 - accuracy: 0.7806\n",
      "Epoch 6/50\n",
      "392/392 [==============================] - 0s 130us/step - loss: 0.4304 - accuracy: 0.8061\n",
      "Epoch 7/50\n",
      "392/392 [==============================] - 0s 148us/step - loss: 0.4254 - accuracy: 0.7934\n",
      "Epoch 8/50\n",
      "392/392 [==============================] - 0s 115us/step - loss: 0.4351 - accuracy: 0.7857\n",
      "Epoch 9/50\n",
      "392/392 [==============================] - 0s 99us/step - loss: 0.4098 - accuracy: 0.8010\n",
      "Epoch 10/50\n",
      "392/392 [==============================] - 0s 161us/step - loss: 0.4083 - accuracy: 0.8010\n",
      "Epoch 11/50\n",
      "392/392 [==============================] - 0s 125us/step - loss: 0.4064 - accuracy: 0.7959\n",
      "Epoch 12/50\n",
      "392/392 [==============================] - 0s 105us/step - loss: 0.4054 - accuracy: 0.8036\n",
      "Epoch 13/50\n",
      "392/392 [==============================] - 0s 122us/step - loss: 0.3975 - accuracy: 0.8061\n",
      "Epoch 14/50\n",
      "392/392 [==============================] - 0s 122us/step - loss: 0.3956 - accuracy: 0.8087\n",
      "Epoch 15/50\n",
      "392/392 [==============================] - 0s 125us/step - loss: 0.3995 - accuracy: 0.8138\n",
      "Epoch 16/50\n",
      "392/392 [==============================] - 0s 122us/step - loss: 0.3983 - accuracy: 0.8061\n",
      "Epoch 17/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3962 - accuracy: 0.8061\n",
      "Epoch 18/50\n",
      "392/392 [==============================] - 0s 125us/step - loss: 0.3914 - accuracy: 0.8214\n",
      "Epoch 19/50\n",
      "392/392 [==============================] - 0s 125us/step - loss: 0.3829 - accuracy: 0.8418\n",
      "Epoch 20/50\n",
      "392/392 [==============================] - 0s 87us/step - loss: 0.3876 - accuracy: 0.8189\n",
      "Epoch 21/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3797 - accuracy: 0.8240\n",
      "Epoch 22/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3794 - accuracy: 0.8316\n",
      "Epoch 23/50\n",
      "392/392 [==============================] - 0s 117us/step - loss: 0.3768 - accuracy: 0.8240\n",
      "Epoch 24/50\n",
      "392/392 [==============================] - 0s 130us/step - loss: 0.3810 - accuracy: 0.8163\n",
      "Epoch 25/50\n",
      "392/392 [==============================] - 0s 130us/step - loss: 0.3678 - accuracy: 0.8316\n",
      "Epoch 26/50\n",
      "392/392 [==============================] - 0s 130us/step - loss: 0.3765 - accuracy: 0.8393\n",
      "Epoch 27/50\n",
      "392/392 [==============================] - 0s 94us/step - loss: 0.3693 - accuracy: 0.8418\n",
      "Epoch 28/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3698 - accuracy: 0.8367\n",
      "Epoch 29/50\n",
      "392/392 [==============================] - 0s 130us/step - loss: 0.3694 - accuracy: 0.8291\n",
      "Epoch 30/50\n",
      "392/392 [==============================] - 0s 214us/step - loss: 0.3655 - accuracy: 0.8265\n",
      "Epoch 31/50\n",
      "392/392 [==============================] - 0s 184us/step - loss: 0.3654 - accuracy: 0.8342\n",
      "Epoch 32/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3617 - accuracy: 0.8393\n",
      "Epoch 33/50\n",
      "392/392 [==============================] - 0s 122us/step - loss: 0.3587 - accuracy: 0.8367\n",
      "Epoch 34/50\n",
      "392/392 [==============================] - 0s 120us/step - loss: 0.3607 - accuracy: 0.8393\n",
      "Epoch 35/50\n",
      "392/392 [==============================] - 0s 133us/step - loss: 0.3602 - accuracy: 0.8367\n",
      "Epoch 36/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3607 - accuracy: 0.8546\n",
      "Epoch 37/50\n",
      "392/392 [==============================] - 0s 189us/step - loss: 0.3633 - accuracy: 0.8367\n",
      "Epoch 38/50\n",
      "392/392 [==============================] - 0s 181us/step - loss: 0.3560 - accuracy: 0.8444\n",
      "Epoch 39/50\n",
      "392/392 [==============================] - 0s 127us/step - loss: 0.3533 - accuracy: 0.8444\n",
      "Epoch 40/50\n",
      "392/392 [==============================] - 0s 102us/step - loss: 0.3618 - accuracy: 0.8418\n",
      "Epoch 41/50\n",
      "392/392 [==============================] - 0s 102us/step - loss: 0.3594 - accuracy: 0.8291\n",
      "Epoch 42/50\n",
      "392/392 [==============================] - 0s 120us/step - loss: 0.3714 - accuracy: 0.8469\n",
      "Epoch 43/50\n",
      "392/392 [==============================] - 0s 107us/step - loss: 0.3545 - accuracy: 0.8546\n",
      "Epoch 44/50\n",
      "392/392 [==============================] - 0s 133us/step - loss: 0.3526 - accuracy: 0.8418\n",
      "Epoch 45/50\n",
      "392/392 [==============================] - 0s 94us/step - loss: 0.3516 - accuracy: 0.8418\n",
      "Epoch 46/50\n",
      "392/392 [==============================] - 0s 117us/step - loss: 0.3524 - accuracy: 0.8418\n",
      "Epoch 47/50\n",
      "392/392 [==============================] - 0s 173us/step - loss: 0.3607 - accuracy: 0.8444\n",
      "Epoch 48/50\n",
      "392/392 [==============================] - 0s 110us/step - loss: 0.3446 - accuracy: 0.8469\n",
      "Epoch 49/50\n",
      "392/392 [==============================] - 0s 112us/step - loss: 0.3451 - accuracy: 0.8495\n",
      "Epoch 50/50\n",
      "392/392 [==============================] - 0s 102us/step - loss: 0.3444 - accuracy: 0.8597\n",
      "Best: 0.7959183580717262, using {'batch_size': 10, 'epochs': 50}\n",
      "0.7780612200802687 (0.016015409295565528) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.7959183580717262 (0.025329886804161168) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.7602040738779672 (0.04695557493229343) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.7959183487965136 (0.04092362400694938) with: {'batch_size': 40, 'epochs': 50}\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    # Create the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model.\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model, verbose = 1)\n",
    "\n",
    "batch_size = [10, 40]\n",
    "epochs = [10, 50]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
    "grid_results = grid.fit(X_standardised, Y)\n",
    "\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune learning rate and dropout rate. Hard code the batch size and training epoch obtained previously. The best model has learning rate of 0.01 and dropout rate of 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desiree\\Anaconda3\\envs\\deeplearnproject\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.733, total=   3.7s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.763, total=   3.3s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    6.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. dropout_rate=0.0, learn_rate=0.001, score=0.808, total=   2.8s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    9.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.756, total=   3.5s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   13.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.771, total=   2.8s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.01 ...............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   15.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ... dropout_rate=0.0, learn_rate=0.01, score=0.831, total=   3.7s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   19.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.771, total=   3.0s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   22.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.733, total=   4.1s\n",
      "[CV] dropout_rate=0.0, learn_rate=0.1 ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   26.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... dropout_rate=0.0, learn_rate=0.1, score=0.831, total=   2.9s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   29.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.725, total=   3.5s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.763, total=   4.0s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.1, learn_rate=0.001, score=0.815, total=   3.4s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.733, total=   3.6s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.809, total=   3.4s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.1, learn_rate=0.01, score=0.838, total=   3.9s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.733, total=   3.5s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.695, total=   3.4s\n",
      "[CV] dropout_rate=0.1, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.1, learn_rate=0.1, score=0.831, total=   3.4s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.718, total=   3.3s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.740, total=   3.8s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.001 ..............................\n",
      "[CV] .. dropout_rate=0.2, learn_rate=0.001, score=0.815, total=   3.8s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.756, total=   5.6s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.740, total=   3.8s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.01 ...............................\n",
      "[CV] ... dropout_rate=0.2, learn_rate=0.01, score=0.815, total=   4.6s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.733, total=   3.9s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.748, total=   3.6s\n",
      "[CV] dropout_rate=0.2, learn_rate=0.1 ................................\n",
      "[CV] .... dropout_rate=0.2, learn_rate=0.1, score=0.700, total=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.6min finished\n",
      "C:\\Users\\Desiree\\Anaconda3\\envs\\deeplearnproject\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7933673416169322, using {'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
      "0.7678571402722475 (0.030710750122669134) with: {'dropout_rate': 0.0, 'learn_rate': 0.001}\n",
      "0.7857142844978644 (0.032344602514417495) with: {'dropout_rate': 0.0, 'learn_rate': 0.01}\n",
      "0.7780612243377433 (0.0402725879136073) with: {'dropout_rate': 0.0, 'learn_rate': 0.1}\n",
      "0.7678571370791416 (0.03693545277935656) with: {'dropout_rate': 0.1, 'learn_rate': 0.001}\n",
      "0.7933673416169322 (0.04452698200410441) with: {'dropout_rate': 0.1, 'learn_rate': 0.01}\n",
      "0.7525510304436391 (0.05726352155661545) with: {'dropout_rate': 0.1, 'learn_rate': 0.1}\n",
      "0.7576530635052797 (0.041729797560808295) with: {'dropout_rate': 0.2, 'learn_rate': 0.001}\n",
      "0.7704081704117813 (0.03229035213501209) with: {'dropout_rate': 0.2, 'learn_rate': 0.01}\n",
      "0.7270408099403187 (0.02004392236020585) with: {'dropout_rate': 0.2, 'learn_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(learn_rate, dropout_rate):\n",
    "    \n",
    "    # Create the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dropout(dropout_rate)) \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model.\n",
    "    adam = Adam(lr = learn_rate)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 10, epochs = 50, verbose = 0)\n",
    "\n",
    "learn_rate = [0.001, 0.01, 0.1]\n",
    "dropout_rate = [0.0, 0.1, 0.2]\n",
    "\n",
    "param_grid = dict(learn_rate=learn_rate, dropout_rate=dropout_rate)\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
    "grid_results = grid.fit(X_standardised, Y)\n",
    "\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune activation function and network weight initialisation. Hard code the batch size, training epoch and learning rate that were obtained previously. The best model uses softmax activation and uses uniform network weight initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desiree\\Anaconda3\\envs\\deeplearnproject\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] activation=softmax, init=uniform ................................\n",
      "[CV] .... activation=softmax, init=uniform, score=0.740, total=   2.1s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... activation=softmax, init=uniform, score=0.779, total=   2.5s\n",
      "[CV] activation=softmax, init=uniform ................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... activation=softmax, init=uniform, score=0.869, total=   2.3s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    6.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... activation=softmax, init=normal, score=0.725, total=   3.5s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... activation=softmax, init=normal, score=0.771, total=   2.9s\n",
      "[CV] activation=softmax, init=normal .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... activation=softmax, init=normal, score=0.862, total=   2.6s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   15.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... activation=softmax, init=zero, score=0.611, total=   2.1s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   18.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... activation=softmax, init=zero, score=0.695, total=   2.5s\n",
      "[CV] activation=softmax, init=zero ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   20.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... activation=softmax, init=zero, score=0.700, total=   2.1s\n",
      "[CV] activation=relu, init=uniform ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   22.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... activation=relu, init=uniform, score=0.725, total=   2.9s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV] ....... activation=relu, init=uniform, score=0.779, total=   3.1s\n",
      "[CV] activation=relu, init=uniform ...................................\n",
      "[CV] ....... activation=relu, init=uniform, score=0.808, total=   2.5s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV] ........ activation=relu, init=normal, score=0.718, total=   2.6s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV] ........ activation=relu, init=normal, score=0.779, total=   2.9s\n",
      "[CV] activation=relu, init=normal ....................................\n",
      "[CV] ........ activation=relu, init=normal, score=0.831, total=   2.9s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV] .......... activation=relu, init=zero, score=0.611, total=   3.0s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV] .......... activation=relu, init=zero, score=0.695, total=   2.6s\n",
      "[CV] activation=relu, init=zero ......................................\n",
      "[CV] .......... activation=relu, init=zero, score=0.700, total=   2.2s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV] ....... activation=tanh, init=uniform, score=0.771, total=   2.1s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV] ....... activation=tanh, init=uniform, score=0.763, total=   2.4s\n",
      "[CV] activation=tanh, init=uniform ...................................\n",
      "[CV] ....... activation=tanh, init=uniform, score=0.838, total=   2.2s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV] ........ activation=tanh, init=normal, score=0.763, total=   2.7s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV] ........ activation=tanh, init=normal, score=0.740, total=   3.1s\n",
      "[CV] activation=tanh, init=normal ....................................\n",
      "[CV] ........ activation=tanh, init=normal, score=0.823, total=   2.4s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV] .......... activation=tanh, init=zero, score=0.611, total=   2.4s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV] .......... activation=tanh, init=zero, score=0.695, total=   2.1s\n",
      "[CV] activation=tanh, init=zero ......................................\n",
      "[CV] .......... activation=tanh, init=zero, score=0.700, total=   2.9s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV] ..... activation=linear, init=uniform, score=0.771, total=   2.6s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV] ..... activation=linear, init=uniform, score=0.771, total=   2.7s\n",
      "[CV] activation=linear, init=uniform .................................\n",
      "[CV] ..... activation=linear, init=uniform, score=0.838, total=   3.2s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV] ...... activation=linear, init=normal, score=0.763, total=   3.0s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV] ...... activation=linear, init=normal, score=0.763, total=   2.6s\n",
      "[CV] activation=linear, init=normal ..................................\n",
      "[CV] ...... activation=linear, init=normal, score=0.831, total=   2.3s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV] ........ activation=linear, init=zero, score=0.611, total=   2.3s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV] ........ activation=linear, init=zero, score=0.695, total=   2.4s\n",
      "[CV] activation=linear, init=zero ....................................\n",
      "[CV] ........ activation=linear, init=zero, score=0.700, total=   2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.5min finished\n",
      "C:\\Users\\Desiree\\Anaconda3\\envs\\deeplearnproject\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.7959183624812535, using {'activation': 'softmax', 'init': 'uniform'}\n",
      "0.7959183624812535 (0.05394679691822502) with: {'activation': 'softmax', 'init': 'uniform'}\n",
      "0.7857142720295458 (0.05659710545962977) with: {'activation': 'softmax', 'init': 'normal'}\n",
      "0.6683673420730902 (0.04092231924913523) with: {'activation': 'softmax', 'init': 'zero'}\n",
      "0.7704081536859883 (0.034159148828236695) with: {'activation': 'relu', 'init': 'uniform'}\n",
      "0.7755102109240026 (0.04624149261633471) with: {'activation': 'relu', 'init': 'normal'}\n",
      "0.6683673420730902 (0.04092231924913523) with: {'activation': 'relu', 'init': 'zero'}\n",
      "0.7908163082842924 (0.03370616130132414) with: {'activation': 'tanh', 'init': 'uniform'}\n",
      "0.7755101941982094 (0.03478923012909107) with: {'activation': 'tanh', 'init': 'normal'}\n",
      "0.6683673420730902 (0.04092231924913523) with: {'activation': 'tanh', 'init': 'zero'}\n",
      "0.793367321698033 (0.03176447518730299) with: {'activation': 'linear', 'init': 'uniform'}\n",
      "0.7857142844978644 (0.03173683426123371) with: {'activation': 'linear', 'init': 'normal'}\n",
      "0.6683673420730902 (0.04092231924913523) with: {'activation': 'linear', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(activation, init):\n",
    "    \n",
    "    # Create the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(8, input_dim = 8, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dense(4, input_dim = 8, kernel_initializer=init, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile the model.\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 10, epochs = 50, verbose = 0)\n",
    "\n",
    "activation = ['softmax', 'relu', 'tanh', 'linear']\n",
    "init = ['uniform', 'normal', 'zero']\n",
    "\n",
    "param_grid = dict(activation=activation, init=init)\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), verbose = 10)\n",
    "grid_results = grid.fit(X_standardised, Y)\n",
    "\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune the number of neurons in the hidden layers. Hard code the batch size, training epoch, learning rate, activation function and network weight initialisation that were obtained previously. The best model has 8 neurons in the 1st layer and 6 neurons in the 2nd layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Desiree\\Anaconda3\\envs\\deeplearnproject\\lib\\site-packages\\sklearn\\model_selection\\_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=4, neuron2=2, score=0.702, total=   2.3s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.779, total=   3.0s\n",
      "[CV] neuron1=4, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=2, score=0.838, total=   2.5s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.748, total=   2.6s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.779, total=   2.8s\n",
      "[CV] neuron1=4, neuron2=4 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   13.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=4, score=0.808, total=   2.3s\n",
      "[CV] neuron1=4, neuron2=6 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   15.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=6, score=0.733, total=   2.5s\n",
      "[CV] neuron1=4, neuron2=6 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   17.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=6, score=0.794, total=   3.0s\n",
      "[CV] neuron1=4, neuron2=6 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   20.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=4, neuron2=6, score=0.823, total=   2.5s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   23.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ neuron1=8, neuron2=2, score=0.718, total=   2.4s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.786, total=   2.4s\n",
      "[CV] neuron1=8, neuron2=2 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=2, score=0.846, total=   3.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.740, total=   2.3s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.779, total=   3.0s\n",
      "[CV] neuron1=8, neuron2=4 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=4, score=0.862, total=   2.1s\n",
      "[CV] neuron1=8, neuron2=6 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=6, score=0.779, total=   2.6s\n",
      "[CV] neuron1=8, neuron2=6 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=6, score=0.786, total=   2.4s\n",
      "[CV] neuron1=8, neuron2=6 ............................................\n",
      "[CV] ................ neuron1=8, neuron2=6, score=0.838, total=   2.6s\n",
      "[CV] neuron1=12, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=2, score=0.763, total=   2.6s\n",
      "[CV] neuron1=12, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=2, score=0.771, total=   3.2s\n",
      "[CV] neuron1=12, neuron2=2 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=2, score=0.823, total=   2.1s\n",
      "[CV] neuron1=12, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=4, score=0.740, total=   2.3s\n",
      "[CV] neuron1=12, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=4, score=0.771, total=   2.0s\n",
      "[CV] neuron1=12, neuron2=4 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=4, score=0.846, total=   2.2s\n",
      "[CV] neuron1=12, neuron2=6 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=6, score=0.733, total=   2.0s\n",
      "[CV] neuron1=12, neuron2=6 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=6, score=0.779, total=   2.2s\n",
      "[CV] neuron1=12, neuron2=6 ...........................................\n",
      "[CV] ............... neuron1=12, neuron2=6, score=0.846, total=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.8010204017770534, using {'neuron1': 8, 'neuron2': 6}\n",
      "0.7729591745503095 (0.055700763011101016) with: {'neuron1': 4, 'neuron2': 2}\n",
      "0.7780612138461094 (0.02431947857888487) with: {'neuron1': 4, 'neuron2': 4}\n",
      "0.7831632742772296 (0.03759812018049345) with: {'neuron1': 4, 'neuron2': 6}\n",
      "0.7831632648499645 (0.052511303001968164) with: {'neuron1': 8, 'neuron2': 2}\n",
      "0.7933673521085661 (0.05049090032359488) with: {'neuron1': 8, 'neuron2': 4}\n",
      "0.8010204017770534 (0.026557574151598942) with: {'neuron1': 8, 'neuron2': 6}\n",
      "0.7857142677720712 (0.02650267600187418) with: {'neuron1': 12, 'neuron2': 2}\n",
      "0.7857142782637051 (0.044365707126585066) with: {'neuron1': 12, 'neuron2': 4}\n",
      "0.7857142981826043 (0.046508593883445554) with: {'neuron1': 12, 'neuron2': 6}\n"
     ]
    }
   ],
   "source": [
    "seed = 9876\n",
    "np.random.seed(seed)\n",
    "\n",
    "def create_model(neuron1, neuron2):\n",
    "    \n",
    "    # Create the model.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1, input_dim = 8, kernel_initializer='uniform', activation='softmax'))\n",
    "    model.add(Dense(neuron2, input_dim = neuron1, kernel_initializer='uniform', activation='softmax'))\n",
    "    model.add(Dense(1, activation='sigmoid')) # sigmoid is used in binary classification\n",
    "    \n",
    "    # Compile the model.\n",
    "    adam = Adam(lr = 0.01)\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = adam, metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model, batch_size = 10, epochs = 50, verbose = 0)\n",
    "\n",
    "neuron1 = [4, 8, 12]\n",
    "neuron2 = [2, 4, 6]\n",
    "\n",
    "param_grid = dict(neuron1 = neuron1, neuron2 = neuron2)\n",
    "\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, cv = KFold(random_state=seed), refit = True, verbose = 10)\n",
    "grid_results = grid.fit(X_standardised, Y)\n",
    "\n",
    "print(\"Best: {0}, using {1}\".format(grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('{0} ({1}) with: {2}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the best model with tuned parameters to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_standardised)\n",
    "print(y_pred[:7].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate model performance metrics. The best model predicted that 262 persons do not have diabetes and 130 persons have diabetes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8698979591836735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       262\n",
      "           1       0.78      0.85      0.81       130\n",
      "\n",
      "    accuracy                           0.87       392\n",
      "   macro avg       0.85      0.87      0.86       392\n",
      "weighted avg       0.87      0.87      0.87       392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y, y_pred))\n",
    "print(classification_report(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3rd data point is actually class 1, but is predicted as class 0 by the model. This is a false negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_pregnant                  3.000\n",
      "glucose_concentration      78.000\n",
      "blood_pressure (mm Hg)     50.000\n",
      "skin_thickness (mm)        32.000\n",
      "serum_insulin (mu U/ml)    88.000\n",
      "BMI                        31.000\n",
      "pedigree_function           0.248\n",
      "age                        26.000\n",
      "class                       1.000\n",
      "Name: 6, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "example = df.iloc[2]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "prediction = grid.predict(X_standardised[2].reshape(1, -1))\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
